import time
import pyaudio
import threading
import dashscope
import streamlit as st

from threading import Timer
from streamlit.elements.widgets.button import *
from streamlit.delta_generator import DeltaGenerator
from streamlit.elements.widgets.button import ButtonMixin
from streamlit.runtime.scriptrunner import add_script_run_ctx
from dashscope.common.error import InvalidParameter,InvalidTask
from dashscope.audio.asr.recognition import Recognition,RecognitionCallback,RecognitionResult

# é‡æ–°å®ç°buttonæ–¹æ³•ï¼Œè®©å…¶èƒ½å¤Ÿå›ºå®šåœ¨èŠå¤©æ¡†åº•éƒ¨
@gather_metrics("button")
def button(
    self,
    label: str,
    key: Key | None = None,
    help: str | None = None,
    on_click: WidgetCallback | None = None,
    args: WidgetArgs | None = None,
    kwargs: WidgetKwargs | None = None,
    *,  # keyword-only arguments:
    type: Literal["primary", "secondary"] = "secondary",
    disabled: bool = False,
    use_container_width: bool = False,
    fix_to_buttom: bool = False,
) -> bool:
    r"""Display a button widget.

    Parameters
    ----------
    label : str
        A short label explaining to the user what this button is for.
        The label can optionally contain Markdown and supports the following
        elements: Bold, Italics, Strikethroughs, Inline Code, and Emojis.

        This also supports:

        * Emoji shortcodes, such as ``:+1:``  and ``:sunglasses:``.
            For a list of all supported codes,
            see https://share.streamlit.io/streamlit/emoji-shortcodes.

        * LaTeX expressions, by wrapping them in "$" or "$$" (the "$$"
            must be on their own lines). Supported LaTeX functions are listed
            at https://katex.org/docs/supported.html.

        * Colored text and background colors for text, using the syntax
            ``:color[text to be colored]`` and ``:color-background[text to be colored]``,
            respectively. ``color`` must be replaced with any of the following
            supported colors: blue, green, orange, red, violet, gray/grey, rainbow.
            For example, you can use ``:orange[your text here]`` or
            ``:blue-background[your text here]``.

        Unsupported elements are unwrapped so only their children (text contents) render.
        Display unsupported elements as literal characters by
        backslash-escaping them. E.g. ``1\. Not an ordered list``.
    key : str or int
        An optional string or integer to use as the unique key for the widget.
        If this is omitted, a key will be generated for the widget
        based on its content. Multiple widgets of the same type may
        not share the same key.
    help : str
        An optional tooltip that gets displayed when the button is
        hovered over.
    on_click : callable
        An optional callback invoked when this button is clicked.
    args : tuple
        An optional tuple of args to pass to the callback.
    kwargs : dict
        An optional dict of kwargs to pass to the callback.
    type : "secondary" or "primary"
        An optional string that specifies the button type. Can be "primary" for a
        button with additional emphasis or "secondary" for a normal button. Defaults
        to "secondary".
    disabled : bool
        An optional boolean, which disables the button if set to True. The
        default is False.
    use_container_width: bool
        An optional boolean, which makes the button stretch its width to match the parent container.

    Returns
    -------
    bool
        True if the button was clicked on the last run of the app,
        False otherwise.

    Example
    -------
    >>> import streamlit as st
    >>>
    >>> st.button("Reset", type="primary")
    >>> if st.button("Say hello"):
    ...     st.write("Why hello there")
    ... else:
    ...     st.write("Goodbye")

    .. output::
        https://doc-buton.streamlit.app/
        height: 220px

    """
    key = to_key(key)
    ctx = get_script_run_ctx()

    # Checks whether the entered button type is one of the allowed options - either "primary" or "secondary"
    if type not in ["primary", "secondary"]:
        raise StreamlitAPIException(
            'The type argument to st.button must be "primary" or "secondary". \n'
            f'The argument passed was "{type}".'
        )

    return self.dg._button(
        label,
        key,
        help,
        is_form_submitter=False,
        on_click=on_click,
        args=args,
        kwargs=kwargs,
        disabled=disabled,
        type=type,
        use_container_width=use_container_width,
        ctx=ctx,
        fix_to_buttom=fix_to_buttom
    )

def _button(
        self,
        label: str,
        key: str | None,
        help: str | None,
        is_form_submitter: bool,
        on_click: WidgetCallback | None = None,
        args: WidgetArgs | None = None,
        kwargs: WidgetKwargs | None = None,
        *,  # keyword-only arguments:
        type: Literal["primary", "secondary"] = "secondary",
        disabled: bool = False,
        use_container_width: bool = False,
        ctx: ScriptRunContext | None = None,
        fix_to_buttom: bool = False,
    ) -> bool:
        key = to_key(key)

        # Importing these functions here to avoid circular imports
        from streamlit.elements.utils import (
            check_cache_replay_rules,
            check_callback_rules,
            check_session_state_rules,
        )

        if not is_form_submitter:
            check_callback_rules(self.dg, on_click)
        check_cache_replay_rules()
        check_session_state_rules(default_value=None, key=key, writes_allowed=False)

        id = compute_widget_id(
            "button",
            user_key=key,
            label=label,
            key=key,
            help=help,
            is_form_submitter=is_form_submitter,
            type=type,
            use_container_width=use_container_width,
            page=ctx.page_script_hash if ctx else None,
        )

        # It doesn't make sense to create a button inside a form (except
        # for the "Form Submitter" button that's automatically created in
        # every form). We throw an error to warn the user about this.
        # We omit this check for scripts running outside streamlit, because
        # they will have no script_run_ctx.
        if runtime.exists():
            if is_in_form(self.dg) and not is_form_submitter:
                raise StreamlitAPIException(
                    f"`st.button()` can't be used in an `st.form()`.{FORM_DOCS_INFO}"
                )
            elif not is_in_form(self.dg) and is_form_submitter:
                raise StreamlitAPIException(
                    f"`st.form_submit_button()` must be used inside an `st.form()`.{FORM_DOCS_INFO}"
                )

        button_proto = ButtonProto()
        button_proto.id = id
        button_proto.label = label
        button_proto.default = False
        button_proto.is_form_submitter = is_form_submitter
        button_proto.form_id = current_form_id(self.dg)
        button_proto.type = type
        button_proto.use_container_width = use_container_width
        button_proto.disabled = disabled

        if help is not None:
            button_proto.help = dedent(help)

        serde = ButtonSerde()

        button_state = register_widget(
            "button",
            button_proto,
            user_key=key,
            on_change_handler=on_click,
            args=args,
            kwargs=kwargs,
            deserializer=serde.deserialize,
            serializer=serde.serialize,
            ctx=ctx,
        )

        if ctx:
            save_for_app_testing(ctx, id, button_state.value)
        
        if fix_to_buttom:
            from streamlit import _bottom
            _bottom._enqueue("button", button_proto)
        else:
            self.dg._enqueue("button", button_proto)

        return button_state.value

ButtonMixin.button = button
ButtonMixin._button = _button

# å›è°ƒå‡½æ•°ï¼Œåœ¨æŸä¸ªæ¡ä»¶ä¸‹ä¼šè°ƒç”¨å…¶æˆå‘˜å‡½æ•°
class Callback(RecognitionCallback):
    def on_open(self) -> None:
        # åˆ›å»ºä¸€ä¸ªPyaudioå®ä¾‹ï¼Œç”¨äºä¸éŸ³é¢‘æ¥å£äº¤äº’ï¼Œæ¯”å¦‚æ‰“å¼€ã€å…³é—­éŸ³é¢‘æµå’Œè·å–è®¾å¤‡ä¿¡æ¯ã€‚
        st.session_state.mic = pyaudio.PyAudio()
        # åˆ›å»ºä¸€ä¸ªéŸ³é¢‘æµï¼Œç”¨äºä»éº¦å…‹é£æˆ–å…¶ä»–éŸ³é¢‘æºè·å–éŸ³é¢‘æ•°æ®ã€‚
        st.session_state.stream = st.session_state.mic.open(
            format=pyaudio.paInt16,  # éŸ³é¢‘æ•°æ®æ ¼å¼,pyaudio.paInt16è¡¨ç¤º16ä½æ·±åº¦
            channels=1,              # æŒ‡å®šéŸ³é¢‘çš„å£°é“æ•°ï¼Œ1è¡¨ç¤ºå•å£°é“Mono
            rate=16000,              # æŒ‡å®šéŸ³é¢‘çš„é‡‡æ ·ç‡ï¼Œ16000è¡¨ç¤ºæ¯ç§’é‡‡æ ·1600æ¬¡
            input=True)              # æŒ‡å®šè¯¥æµç”¨äºè¾“å…¥ï¼Œç”¨äºä»éº¦å…‹é£æˆ–å…¶ä»–éŸ³é¢‘æºè·å–éŸ³é¢‘æ•°æ®
    
    def on_close(self) -> None:
        if st.session_state.stream:
            # å…³é—­éŸ³é¢‘æµï¼Œé˜²æ­¢ç»§ç»­è¯»å–æ•°æ®
            st.session_state.stream.stop_stream()
            st.session_state.stream.close()
            st.session_state.stream = None
        if st.session_state.mic:
            # å…³é—­PyAudioå®ä¾‹ï¼Œé‡Šæ”¾èµ„æº
            st.session_state.mic.terminate()
            st.session_state.mic = None
    
    def on_event(self, result: RecognitionResult) -> None:
        # å¤„ç†æ¯ä¸€æ¬¡è½¬å†™ç»“æœ
        st.session_state.transform_res = result
        print("RecognitionCallback sentence: ", result.get_sentence())

    def on_complete(self) -> None:
        # å½“è¯†åˆ«å…¨éƒ¨å®Œæˆæ—¶è°ƒç”¨
        print("RecognitionCallback on_completeï¼š", st.session_state.transform_res.get_sentence())

# çˆ¶ç±»è°ƒç”¨Callbackæ˜¯åœ¨å¿åŸé‡Œè°ƒç”¨çš„ï¼Œæ‰€ä»¥å¾—é‡æ–°å®ç°startæ–¹æ³•
# ä¸ºè¿™ä¸ªè°ƒç”¨callbackçš„çº¿ç¨‹æ·»åŠ ä¸€ä¸ªadd_script_run_ctxï¼Œè¿™æ ·æ‰èƒ½å¤Ÿåœ¨æ–°çš„çº¿ç¨‹çš„éš”ç¦»çš„ç¯å¢ƒä¸­ï¼Œä¿æŒst.session_stateçš„å€¼ä¸ä¸»çº¿ç¨‹çš„ä¸€è‡´ã€‚
class myRecognition(Recognition):
    def __init__(self, model: str, callback: RecognitionCallback, format: str, sample_rate: int, workspace: str = None, **kwargs):
        super().__init__(model, callback, format, sample_rate, workspace, **kwargs)
    
    def start(self, phrase_id: str = None, **kwargs):
        """Real-time speech recognition in asynchronous mode.
           Please call 'stop()' after you have completed recognition.

        Args:
            phrase_id (str, `optional`): The ID of phrase.

            **kwargs:
                disfluency_removal_enabled(bool, `optional`):
                    Filter mood words, turned off by default.
                diarization_enabled (bool, `optional`):
                    Speech auto diarization, turned off by default.
                speaker_count (int, `optional`): The number of speakers.
                timestamp_alignment_enabled (bool, `optional`):
                    Timestamp-alignment calibration, turned off by default.
                special_word_filter(str, `optional`): Sensitive word filter.
                audio_event_detection_enabled(bool, `optional`):
                    Audio event detection, turned off by default.

        Raises:
            InvalidParameter: This interface cannot be called again
                if it has already been started.
            InvalidTask: Task create failed.
        """
        assert self._callback is not None, 'Please set the callback to get the speech recognition result.'  # noqa E501

        if self._running:
            raise InvalidParameter('Speech recognition has started.')

        self._phrase = phrase_id
        self._kwargs.update(**kwargs)
        self._recognition_once = False
        self._worker = add_script_run_ctx(threading.Thread(target=self.__receive_worker))
        self._worker.start()
        if self._worker.is_alive():
            self._running = True
            self._callback.on_open()

            # If audio data is not received for 23 seconds, the timeout exits
            self._silence_timer = Timer(Recognition.SILENCE_TIMEOUT_S,
                                        self._silence_stop_timer)
            self._silence_timer.start()
        else:
            self._running = False
            raise InvalidTask('Invalid task, task create failed.') 

def session_state_variables():
    # å®šä¹‰å…¨å±€å˜é‡
    # åˆ†åˆ«å®šä¹‰ï¼š
    # mic éº¦å…‹é£å¯¹è±¡
    # stream éŸ³é¢‘æµå¯¹è±¡
    # recognition è¯­éŸ³è¯†åˆ«å¯¹è±¡
    # recognition_activte è¯­éŸ³è¯†åˆ«æ˜¯å¦æ¿€æ´»çš„æ ‡å¿—ã€‚æŠŠå…¶æ”¾åœ¨session_stateä¸­ï¼Œæ˜¯å› ä¸ºç¬¬äºŒæ¬¡ç‚¹å‡»é¡µé¢ä¼šé‡æ–°æ‰§è¡Œæ•´ä¸ªç¨‹åºï¼Œè¿™æ ·ä¼šæŠŠè¿™ä¸ªæ ‡å¿—é‡ç½®ã€‚
    # exit_program ç¨‹åºæ˜¯å¦éœ€è¦æ¨å‡ºçš„æ ‡å¿—
    # lock çº¿ç¨‹é”ï¼Œç”¨äºåŒæ­¥æ“ä½œã€‚lockè¦æ”¾åœ¨session_stateä¸­ï¼Œå› ä¸ºç¬¬äºŒæ¬¡ç‚¹å‡»é¡µé¢ä¼šé‡æ–°åˆ›å»ºä¸€ä¸ªçº¿ç¨‹ã€‚
    # transform_res å­˜å‚¨Callbackç±»æ¯æ¬¡è½¬å†™çš„ç»“æœï¼Œå½“æ—¶åˆ«å®Œæˆæ—¶ï¼Œè¿™ä¸ªå˜é‡è®°å½•çš„å°±æ˜¯æœ€æœ‰ä¸€æ¬¡å®Œæ•´çš„è¯†åˆ«ç»“æœã€‚

    if 'mic' not in st.session_state:
        st.session_state.mic = None
    
    if 'stream' not in st.session_state:
        st.session_state.stream = None
    
    if 'recognition' not in st.session_state:
        st.session_state.recognition = None

    if 'recognition_activte' not in st.session_state:
        st.session_state.recognition_activte = False

    if 'exit_program' not in st.session_state:
        st.session_state.exit_program = False

    if 'lock' not in st.session_state:
        st.session_state.lock = threading.Lock()

    if 'transform_res' not in st.session_state:
        st.session_state.transform_res = None

def lingji_stt_st() -> str:
    # å®šä¹‰è¯­éŸ³è¯†åˆ«çš„å‡½æ•°

    # ä¸èƒ½å¤Ÿæ”¾åœ¨pythonæ–‡ä»¶çš„ç¬¬ä¸€çº§æ‰§è¡Œï¼Œå¾—æ¯æ¬¡éƒ½æ‰§è¡Œä¸€éã€‚
    # è¿™é‡Œæ˜¯å­æ–‡ä»¶ï¼Œä¸æ˜¯ä¸»æ–‡ä»¶ï¼ŒStreamlitåº”è¯¥åªä¼šæ‰§è¡Œå­æ–‡ä»¶é‡Œçš„è¢«ä¸»æ–‡ä»¶è°ƒç”¨çš„ä»£ç ã€‚
    # å½“æˆ‘åˆ·æ–°æ—¶ï¼Œå°±ç›¸å½“äºåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„sessionï¼Œä½†å¦‚æœæ”¾åœ¨ç¬¬ä¸€çº§çš„è¯ï¼Œå­æ–‡ä»¶é‡Œçš„è¿™äº›ifè¯­å¥å°±ä¸ä¼šè¢«æ‰§è¡Œã€‚
    session_state_variables()

    # éœ€è¦æŠŠåˆ›å»ºçš„è¯­éŸ³è¯†åˆ«å®ä¾‹æ”¾åœ¨session_stateä¸­ï¼Œå› ä¸ºæ¯æ¬¡è¿è¡Œæ•´ä¸ªç¨‹åºæ—¶ï¼Œå¦‚æœä¸æ”¾å…¥çš„è¯ï¼Œ
    # å°±ä¼šé‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„è¯­éŸ³è¯†åˆ«å®ä¾‹ï¼Œç„¶åä¸‹é¢çš„ä»£ç ä¼šç›´æ¥è°ƒç”¨è¿™ä¸ªæ–°çš„å®ä¾‹çš„.stopæ–¹æ³•ã€‚
    if st.session_state.recognition is None:
        dashscope.api_key = 'sk-xx'
        st.session_state['recognition'] = myRecognition(
            model="paraformer-realtime-v1",  # è¯­éŸ³è¯†åˆ«æ¨¡å‹
            format='pcm',                    # éŸ³é¢‘æ ¼å¼
            sample_rate=16000,               # æŒ‡å®šéŸ³é¢‘çš„é‡‡æ ·ç‡ï¼Œ16000è¡¨ç¤ºæ¯ç§’é‡‡æ ·16000æ¬¡ã€‚
            callback=Callback()              # å›è°ƒå‡½æ•°ï¼Œåœ¨æŸä¸ªæ¡ä»¶ä¸‹ä¼šè°ƒç”¨å…¶æˆå‘˜å‡½æ•°ã€‚
        )
    
    # æ·»åŠ è§¦å‘æŒ‰é’®
    if 'dg' not in st.session_state:
        st.session_state.dg = DeltaGenerator()
    if ButtonMixin.button(st.session_state.dg, "ğŸ¤", fix_to_buttom=True):
        if not st.session_state.recognition_activte:           # å¦‚æœæ²¡æœ‰æ¿€æ´»è¯­éŸ³è¯†åˆ«
            with st.session_state.lock:                        # ä½¿ç”¨çº¿ç¨‹é”
                st.session_state.recognition_activte = True    # è®¾ç½®è¯†åˆ«æ¿€æ´»æ ‡å¿—
                st.session_state.recognition.start()           # å¼€å§‹è¯­éŸ³è¯†åˆ«

                if 'stt_thread' not in st.session_state:
                    # è®¾ç½®ä¸ºå®ˆæŠ¤è¿›ç¨‹ï¼Œå½“ä¸»ç¨‹åºå´©æºƒæ—¶ï¼Œå…¶ä¹Ÿä¼šè‡ªåŠ¨ç»“æŸã€‚
                    st.session_state.stt_thread = threading.Thread(target=mystt, daemon=True)
                    st.session_state.stt_thread = add_script_run_ctx(st.session_state.stt_thread)
                    st.session_state.stt_thread.start()
        else:                                                  # å¦‚æœå·²ç»æ¿€æ´»è¯†åˆ«
            with st.session_state.lock:                        # ä½¿ç”¨çº¿ç¨‹é”
                st.session_state.recognition_activte = False   # å–æ¶ˆè¯†åˆ«æ¿€æ´»æ ‡å¿—
                st.session_state.recognition.stop()            # åœæ­¢è¯­éŸ³è¯†åˆ«
                st.session_state.recognition = None            # å› ä¸ºstopæ—¶å·²ç»åˆ é™¤æ‰äº†ä¸€äº›ç»„ä»¶ï¼Œæ‰€ä»¥æŠŠè¯­éŸ³è¯†åˆ«å®ä¾‹åˆ é™¤æ‰ï¼Œä¸‹æ¬¡å†é‡æ–°åˆ›å»ºã€‚
            
            return st.session_state.transform_res.get_sentence()['text']
        
def mystt():
    while not st.session_state.exit_program:  # ä¸»å¾ªç¯ï¼Œç›´åˆ°è®¾ç½®é€€å‡ºæ ‡å¿—
        # ä½¿ç”¨çº¿ç¨‹é”ï¼ŒåŒä¸€æ—¶åˆ»ï¼Œåªæœ‰ä¸€ä¸ªçº¿ç¨‹èƒ½å¤Ÿè·å¾—è¯¥é”ï¼Œå¹¶æ‰§è¡Œé”ä¸‹çš„ä»£ç ï¼Œä»£ç å¯ä»¥ä¸åŒã€‚
        # é˜²æ­¢ä¸»çº¿ç¨‹åœ¨æ‰§è¡Œå¾ªç¯çš„æ—¶å€™ï¼Œstreamæˆ–è€…æ˜¯recognitionå¯¹è±¡çªç„¶å˜æˆNoneï¼ˆæ‰§è¡Œifçš„æ—¶å€™è¿˜ä¸æ˜¯Noneï¼Œä½†è¿›å»ifåˆ†æ”¯åå°±å˜æˆNoneäº†ï¼‰
        # æ‰€ä»¥åœ¨on_presså‡½æ•°çš„elseåˆ†æ”¯é‚£é‡Œéœ€è¦ç”¨åŒä¸€ä¸ªé”ã€‚
        with st.session_state.lock:  
            if st.session_state.recognition_active and st.session_state.stream:  # å¦‚æœè¯†åˆ«å·²ç»æ¿€æ´»ä¸”éŸ³é¢‘æµå­˜åœ¨
                try:
                    data = st.session_state.stream.read(3200, exception_on_overflow=False)  # è¯»å–éŸ³é¢‘æ•°æ®
                    st.session_state.recognition.send_audio_frame(data)  # å‘é€éŸ³é¢‘æ•°æ®è¿›è¡Œè¯†åˆ«
                except:
                    pass  # å¿½ç•¥é”™è¯¯
        time.sleep(0.01)  # æ¯æ¬¡å¾ªç¯åç­‰å¾…100æ¯«ç§’ï¼Œé˜²æ­¢CPUå ç”¨è¿‡é«˜  

if __name__ == "__main__":
    dg = DeltaGenerator()
    ButtonMixin.button(dg, "ğŸ¤", fix_to_buttom=True)